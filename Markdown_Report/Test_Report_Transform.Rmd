---
title: "Test Report"
author: Researcher A
output: officedown::rdocx_document
date: "`r Sys.Date()`"
page_size:
      width: 8.3
      height: 11.7
      orient: "portrait"
page_margins:
      bottom: 0.5
      top: 0.5
      right: 0.5
      left: 0.5
      header: 0.5
      footer: 0.5
      gutter: 0.5


---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  dpi = 300
)
library(officedown)
library(flextable)
library(tidyverse)
library(officer)
library(ggpubr)
source("word_tables.R")
```

# Background

Insert information provided on the Session setup page

# Statistical Methods

## Mixed Effects Modeling

A mixed effects model is well suited for evaluating statistical differences between multiple experimental (treatment) groups across multiple times points. This can be accomplished by using a 2 factor model with interaction where the model terms are treatment, time, and treatment*time (interaction). Mixed effects models can incorporate the within subject correlation between different time points. Some common correlation structures include auto-regressive (AR1) correlation structure which assumes that the correlation between time points decays at an exponential rate, compound symmetry (CS) correlation structure assumes that the correlation between time points is constant between any given time points, and unstructured is the most flexible and has no constraints. 

Mixed effects models can model the variance/covariance structure of each group separately, i.e. the correlation matrix for each group is not required to be the same. While many of the typical regression assumptions are still applicable with mixed models especially that the model residuals are normally distributed.

## Checking Model Assumptions

### Normality and Transformation

A Shapiro-Wilk test is conducted to determine if the residuals of a linear model with a treatment, time, and treatment\*time interaction term. If the Shapiro-Wilk test is rejected, then a Box-Cox transformation is conducted to suggest an appropriate transformation. Then another Shapiro-Wilk test is conducted on a linear model with a treatment, time, and treatment\*time term using the transformed data to ensure that the transformation helped address the normality assumption. If the Shapiro-Wilk test is rejected, then we recommend further discussion with a statistician as a transformation did not make data follow the normality assumption.

No transformation was required or
A [insert transformation] was applied to the data. 

## Checking for Similar Variance between Groups

### Basic Model

We will denote the treatment groups (doses) and the non-wild type vehicle as the basic model. For this application, we require that the variance for each of the groups in the basic model are similar. To verify this assumption, first the variance is determined for each group and at each time point, and then averaged across the time points. A likelihood ratio test (LRT) is conducted between a model that estimates one common variance and a model that estimates an individual variance for each group. If the LRT is rejected and there is a 2 fold change between any group and the pooled variance then a statistician should be consulted. Alternatively, if we fail to reject the LRT and there is a 3 fold change between any group and the pooled variance then a statistician should be consulted. Otherwise, the application will move forward to the next modeling step.

### Controls and Wild Type

Once the variance for groups within basic model is determined to be similar, then a similar procedure is followed as above. A LRT is conducted for a model that has a common variance and a model that a common variance for the groups in the basic model and a different variance for the controls and wild type. If the LRT is rejected and there is a 2 fold change between the variance of controls or wild type and the basic model, then mixed effects model will estimate multiple variance components for the differing group.  Alternatively, if we fail to reject the LRT and there is a 3 fold change between the variance of controls or wild type and the basic model, then mixed effects model will estimate the different variance components for the differing groups. Otherwise, the application will move forward to fit the final mixed model with one single common varaince component.

All groups have similar variance 
or
[insert group] had a different variance from the basic model.

## Selection of Correlation Sturcture

The Akaike Information Criterion (AIC) is used to select the correlation structure that is most appropriate. The AIC strikes a balance between model complexity and quality of the model fit. The candidate correlation structures are AR1 (ARH1), CS (CSH), Toeplitz (TOEP), and unstructured (UN). 

[insert correlation structure] had the smallest AIC.

## Comparison between Experimental Groups

There are 9 group comparisons that have relevant interpretation:

```{r, echo = F, fig.cap='List of the 9 combinations of experimental groups and their interpretation.'}
contrasts <- data.frame(
  Label = LETTERS[1:9],
  Group_1 = c(
    "Wild Type",
    "Positive Control",
    "Wild Type",
    "Vehicle",
    "Wild Type",
    "Positive Control",
    "Dose",
    "Negative Control",
    "Negative Control"
  ),
  Group_2 = c(
    "Vehicle",
    "Vehicle",
    "Dose",
    "Dose",
    "Positive Control",
    "Dose",
    "Dose",
    "Vehicle",
    "Dose"
  ),
  `Purpose of Comparison` = c(
    "Verify Disease Model",
    "Verify Positive Control",
    "Which doses are similar to Wild Type?",
    "Which treatment doses are effective?",
    "Does Positive Control reverse disease?",
    "Which doses are similar to Positive Control",
    "Do doses differ from each other?",
    "Rule out matrix effect",
    "If H is rejected, then show Negative Control is not as good as treatment"
  ),
  check.names = FALSE
)

contrasts_ft <- flextable(contrasts)
contrasts_ft <- width(contrasts_ft, width = c(0.75, 1, 1, 3))
contrasts_ft <- fontsize(contrasts_ft, size = 9, part = "header")
contrasts_ft <- fontsize(contrasts_ft, size = 8)
contrasts_ft
```

## Multiple Hypothesis Testing

Within the contrasts that involve treatment doses there are multiple comparisons that are being made and thus adjusting the p-values for these comparisons is important to maintain the desired family-wise Type I error rate. In many cases, the p-value adjust method may vary based on the comparison, but a simulation based methods (determines critical values and p-values based on sampling from the multivariate t distribution) are available that are well suited for most scenarios. 

In addition to testing these hypotheses at a specific time point, testing of these hypothesis can be conducted across all time points. This will double the number of hypothesis tests conducted for each group comparison. Adjusting for multiple comparisons is necessary and will be accommodated using the simulation based method.   

## Technical Replicates

In experiments that have technical replication, all of the data will be used to check the normality assumption  and subsequently determine the most appropriate Box-Cox transformation (treating technical replicates as independent). After this step, the technical replicates will be averaged at each time point for each subject. The resulting dataset will be used for all of the remaining analysis steps. 

## Change from Baseline Analysis

The user will be allowed to select whether the raw/transformed values are to be analysed or to analysis the change of each observation from a subject's baseline measurement. The normality check and Box-Cox transformation will be conducted ignoring the baseline, then the change from baseline will be the response studied for the remainder of the analysis. 

## Workflow Illustration

![](TEST_workflow.png)
\newpage

# Results

## Plots (One per page? or two per page?)
```{r, echo = F, error=F, warning=FALSE, fig.align='center', fig.width=7, fig.height=4}
load("C:/Users/Christopher.Wilson/Desktop/Test_Report/plots.RData")

# plots[[1]] +
#   theme(plot.title = element_text(size = 10),
#         axis.title = element_text(size = 10),
#         axis.text.x = element_text(size = 6),
#         axis.text.y = element_text(size = 8),
#         strip.text = element_text(size = 8),
#         legend.position = 'bottom') +
#   geom_point(aes(color = Treatment), size = 0.7) +
#     stat_summary(fun = "mean", color = "black", show.legend = FALSE, size = 0.0)

test_plot_theme_html <- function(x) {
  theme(
    plot.title = element_text(size = 12),
    axis.title = element_text(size = 10),
    axis.text.x = element_text(angle = 45, vjust = 0.75, hjust = 0.75, size = 7),
    axis.text.y = element_text(size = 8),
    strip.text = element_text(size = 8),
    legend.text = element_text(size = 8),
    legend.title = element_text(size = 10),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank()
  )
}

ggplot(data = plots[[1]]$data, aes(x = Time, y = Response_Transformed, label = SubjectID)) +
  geom_boxplot(aes(color = Treatment), outlier.size = 1) +
  geom_jitter(width = 0.1, aes(color = Treatment), size = 0.5) +
  theme_bw() +
  labs(color = "Treatment") +
  facet_wrap(Treatment ~ ., nrow = 1) +
  ylab(plots[[1]]$labels$y) +
  stat_summary(fun = "mean", color = "black", show.legend = FALSE, size = 0.2) +
  ggtitle("Box Plot for Each Group Over Time") +
  test_plot_theme_html() +
  theme(legend.position = "none")
```

```{r, echo=F, error=F, warning=FALSE, fig.align='center', fig.width=7, fig.height=4}
plots[[2]] +
  test_plot_theme_html() +
  theme(
    legend.position = "bottom"
  )
```

```{r, echo=F, error=F, warning=FALSE, fig.align='center', fig.width=7, fig.height=4}
plots[[3]] +
  test_plot_theme_html() +
  theme(
    legend.position = "bottom"
  )
```


```{r, echo=F, error=F, warning=FALSE, fig.align='center', fig.width=7, fig.height=4}

plots[[4]] +
  test_plot_theme_html() +
  theme(
    legend.position = "bottom"
  )
```
\newpage

## Original Scale Summary 
```{r, echo = F, error=F, warning=FALSE}
load("C:/Users/Christopher.Wilson/Desktop/Test_Report/trans_table.RData")

tab0 <- dplyr$bind_rows(tab1, tab2) %>%
  dplyr$select(
    Treatment, `Times Included`,
    grep("Original Scale", colnames(.), value = TRUE)
  )

word_tables(data = tab0, summary_only = T)
```


## Table 1

```{r, echo = F, error=F, warning=FALSE}
# tab1 = read.csv('C:/Users/Christopher.Wilson/Desktop/Test_Report/tab1.csv', check.names = F) %>%
#  dplyr$select(-1) %>%
#  dplyr$mutate(`Times Included` = ifelse(`Times Included` == 'Average Over Time', 'Overall Average',
#                                     `Times Included`))

word_tables(data = tab1, include_summ_stat = T, transform = T, summary_only = F)
```
<!---BLOCK_LANDSCAPE_START--->

## Table 2

```{r, echo = F, error=F, warning=FALSE}
# tab2 = read.csv('C:/Users/Christopher.Wilson/Desktop/Test_Report/tab2.csv', check.names = F) %>%
#  dplyr$select(-1) %>%
#  dplyr$mutate(`Times Included` = ifelse(`Times Included` == 'Average Over Time', 'Overall Average',
#                                     `Times Included`))

word_tables(data = tab2, include_summ_stat = T, transform = T, summary_only = F)
```



<!---BLOCK_LANDSCAPE_STOP--->

## Table 3
```{r, echo = FALSE, error=F, warning=FALSE}
# tab3 = read.csv('C:/Users/Christopher.Wilson/Desktop/Test_Report/tab3.csv', check.names = F) %>%
#   dplyr$select(-1) %>%
#  dplyr$mutate(`Times Included` = ifelse(`Times Included` == 'Average Over Time', 'Overall Average',
#                                     `Times Included`))
#

word_tables(data = tab3, include_summ_stat = F, transform = T, summary_only = F)
```

